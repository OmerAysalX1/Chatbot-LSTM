{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "927e3c97-316f-4822-a1af-dbe5a15682be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (0.17.2)\n",
      "Requirement already satisfied: torchaudio in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: networkx in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: filelock in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: sympy in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: fsspec in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: numpy in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f889c-f9de-4854-ae78-90a9fecd37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/bartosz-paternoga/Chatbot/blob/master/sample_conversations.csv\n",
    "https://github.com/AnMol12499/LSTM_based_chatbot/blob/main/intents.json\n",
    "https://github.com/LuisFMCuriel/Chatbot/blob/master/Main.py\n",
    "https://github.com/ZithaChitra/simple_chatbot/blob/master/model.py 7777777\n",
    "\n",
    "https://github.com/IshaDagar/CHATBOT-for-helping-people-who-are-stressed-/blob/main/train_chatbot.py\n",
    "https://github.com/Enkhai/pytorch-chatbot/blob/master/models.py\n",
    "https://github.com/Clemagda/AI-Chat-bot/blob/main/chatgui.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd5e7371-d3ab-4b89-897a-ac78dc8c22ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (0.17.2)\n",
      "Requirement already satisfied: numpy in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from torchtext) (1.24.4)\n",
      "Requirement already satisfied: requests in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from torchtext) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from torchtext) (4.64.1)\n",
      "Requirement already satisfied: torch==2.2.2 in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from torchtext) (2.2.2)\n",
      "Requirement already satisfied: networkx in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from torch==2.2.2->torchtext) (2.8.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from torch==2.2.2->torchtext) (4.11.0)\n",
      "Requirement already satisfied: fsspec in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from torch==2.2.2->torchtext) (2024.3.1)\n",
      "Requirement already satisfied: filelock in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from torch==2.2.2->torchtext) (3.6.0)\n",
      "Requirement already satisfied: sympy in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from torch==2.2.2->torchtext) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from torch==2.2.2->torchtext) (3.1.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from requests->torchtext) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from requests->torchtext) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from requests->torchtext) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from requests->torchtext) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch==2.2.2->torchtext) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/omeraysal/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch==2.2.2->torchtext) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8158e290-0278-4274-8165-550796768eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71cd987e-ccac-4176-9a62-d0874e54f65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b868293c-8d03-40fe-936a-b9d46ff25654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.txt', header=None, sep=';', names=['Input', 'Sentiment'], encoding='utf-8')\n",
    "df_test = pd.read_csv('test.txt', header=None, sep=';', names=['Input', 'Sentiment'], encoding='utf-8')\n",
    "df_val = pd.read_csv('va.txt', header=None, sep=';', names=['Input', 'Sentiment'], encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd8433ba-e093-4ebe-930d-9b3cec54d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def gather_tokens(data_iter):\n",
    "    tokens = []\n",
    "    for text in data_iter:\n",
    "        tokens.extend(tokenizer(text))\n",
    "    return tokens\n",
    "\n",
    "# Tüm tokenleri tek bir listede topluyoruz\n",
    "all_tokens = gather_tokens(df_train['Input'])\n",
    "\n",
    "# Bu token listesinden kelime hazinesi oluşturuyoruz\n",
    "vocab = build_vocab_from_iterator([all_tokens], specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b153ec80-16ae-41e3-bf64-9a0b0dc9c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pipeline(x):\n",
    "    return vocab(tokenizer(x))\n",
    "\n",
    "def pad_sequence_fn(batch):\n",
    "    batch = [torch.tensor(text_pipeline(item), dtype=torch.long) for item in batch]\n",
    "    return pad_sequence(batch, padding_value=vocab[\"<unk>\"], batch_first=True)\n",
    "\n",
    "X_train = []\n",
    "for text in df_train['Input']:\n",
    "    X_train.append(text_pipeline(text))\n",
    "\n",
    "X_val = []\n",
    "for text in df_val['Input']:\n",
    "    X_val.append(text_pipeline(text))\n",
    "\n",
    "X_test = []\n",
    "for text in df_test['Input']:\n",
    "    X_test.append(text_pipeline(text))\n",
    "\n",
    "\n",
    "X_train_pad = pad_sequence_fn(df_train['Input'])\n",
    "X_val_pad = pad_sequence_fn(df_val['Input'])\n",
    "X_test_pad = pad_sequence_fn(df_test['Input'])\n",
    "\n",
    "label_dict = {'joy': 0, 'anger': 1, 'love': 2, 'sadness': 3, 'fear': 4, 'surprise': 5}\n",
    "Y_train = df_train['Sentiment'].replace(label_dict).values\n",
    "Y_val = df_val['Sentiment'].replace(label_dict).values\n",
    "Y_test = df_test['Sentiment'].replace(label_dict).values\n",
    "\n",
    "Y_train_f = torch.eye(6)[Y_train]\n",
    "Y_val_f = torch.eye(6)[Y_val]\n",
    "Y_test_f = torch.eye(6)[Y_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89ca1d66-045f-46e4-a5f2-6f64d1ab0645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.labels[idx]\n",
    "\n",
    "train_dataset = EmotionDataset(X_train_pad, Y_train_f)\n",
    "val_dataset = EmotionDataset(X_val_pad, Y_val_f)\n",
    "test_dataset = EmotionDataset(X_test_pad, Y_test_f)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d86fdb33-a273-4078-80e2-7ceafddfaa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super(EmotionModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded)\n",
    "        if self.lstm.bidirectional:\n",
    "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1,:,:])\n",
    "        output = self.fc(hidden)\n",
    "        return output\n",
    "\n",
    "model = EmotionModel(vocab_size=len(vocab), embedding_dim=64, hidden_dim=80, output_dim=6, n_layers=2, bidirectional=False, dropout=0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18103e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class EmotionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        nn.Module.__init__(self)\n",
    "        \n",
    "        # Kelime gömme (embedding) katmanı\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # LSTM katmanı\n",
    "        self.lstm = nn.LSTM(embedding_dim,\n",
    "                            hidden_dim,\n",
    "                            num_layers=n_layers,\n",
    "                            bidirectional=bidirectional,\n",
    "                            dropout=dropout,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        # Tam bağlantılı (fully connected) katman\n",
    "        if bidirectional:\n",
    "            self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        # Dropout katmanı\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        # Gömme katmanı\n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        # Dropout\n",
    "        embedded_dropout = self.dropout(embedded)\n",
    "        \n",
    "        # LSTM katmanı\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded_dropout)\n",
    "        \n",
    "        # Son gizli durumu al\n",
    "        if self.lstm.bidirectional:\n",
    "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        else:\n",
    "            hidden = hidden[-1,:,:]\n",
    "        \n",
    "        # Dropout\n",
    "        hidden_dropout = self.dropout(hidden)\n",
    "        \n",
    "        # Tam bağlantılı katman\n",
    "        output = self.fc(hidden_dropout)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Model oluşturma\n",
    "model = EmotionModel(vocab_size=len(vocab),\n",
    "                     embedding_dim=64,\n",
    "                     hidden_dim=80,\n",
    "                     output_dim=6,\n",
    "                     n_layers=2,\n",
    "                     bidirectional=True,\n",
    "                     dropout=0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53f0c90e-b5f2-4d26-a5af-4124c223d9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.588, Val Loss: 1.566\n",
      "Epoch 2, Train Loss: 1.553, Val Loss: 1.487\n",
      "Epoch 3, Train Loss: 1.482, Val Loss: 1.354\n",
      "Epoch 4, Train Loss: 1.393, Val Loss: 1.120\n",
      "Epoch 5, Train Loss: 1.249, Val Loss: 0.929\n",
      "Epoch 6, Train Loss: 1.123, Val Loss: 0.786\n",
      "Epoch 7, Train Loss: 1.004, Val Loss: 0.657\n",
      "Epoch 8, Train Loss: 0.916, Val Loss: 0.591\n",
      "Epoch 9, Train Loss: 0.843, Val Loss: 0.505\n",
      "Epoch 10, Train Loss: 0.757, Val Loss: 0.464\n",
      "Epoch 11, Train Loss: 0.692, Val Loss: 0.400\n",
      "Epoch 12, Train Loss: 0.625, Val Loss: 0.374\n",
      "Epoch 13, Train Loss: 0.590, Val Loss: 0.323\n",
      "Epoch 14, Train Loss: 0.540, Val Loss: 0.290\n",
      "Epoch 15, Train Loss: 0.494, Val Loss: 0.268\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        text, labels = batch\n",
    "        text = text.to(device)\n",
    "        labels = labels.to(device)\n",
    "        predictions = model(text)\n",
    "        loss = criterion(predictions, torch.max(labels, 1)[1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, labels = batch\n",
    "            text = text.to(device)\n",
    "            labels = labels.to(device)\n",
    "            predictions = model(text)\n",
    "            loss = criterion(predictions, torch.max(labels, 1)[1])\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "n_epochs = 15\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss = evaluate(model, val_loader, criterion)\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.3f}, Val Loss: {val_loss:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8118906-56e9-4bad-9ac8-715e1dcda631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.245\n",
      "sadness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/f6l__m_960b6hcgcw1vdk_wr0000gn/T/ipykernel_1077/3074684875.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sentence_tensor = torch.tensor(sentence_padded, dtype=torch.long).to(device)\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(model, test_loader, criterion)\n",
    "print(f'Test Loss: {test_loss:.3f}')\n",
    "\n",
    "def get_key(value):\n",
    "    dictionary = {0: 'joy', 1: 'anger', 2: 'love', 3: 'sadness', 4: 'fear', 5: 'surprise'}\n",
    "    return dictionary[value]\n",
    "\n",
    "def predict(sentence, tokenizer, model, maxlen=80):\n",
    "    model.eval()\n",
    "    sentence_lst = [sentence]\n",
    "    sentence_seq = [text_pipeline(sentence) for sentence in sentence_lst]\n",
    "    sentence_padded = pad_sequence_fn(sentence_lst)\n",
    "    sentence_tensor = torch.tensor(sentence_padded, dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        prediction = model(sentence_tensor)\n",
    "        predicted_class = prediction.argmax(dim=1).item()\n",
    "    return get_key(predicted_class)\n",
    "\n",
    "print(predict(\"The heavy rain poured down, drenching the deserted streets, casting a gloomy shadow over the city.\", tokenizer, model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f61e2-3667-4e24-8c89-7165fa15eb55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
